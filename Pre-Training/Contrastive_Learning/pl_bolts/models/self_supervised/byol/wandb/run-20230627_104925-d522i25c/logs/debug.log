2023-06-27 10:49:25,720 INFO    MainThread:2866468 [wandb_setup.py:_flush():75] Loading settings from /home/wolfda/.config/wandb/settings
2023-06-27 10:49:25,720 INFO    MainThread:2866468 [wandb_setup.py:_flush():75] Loading settings from /home/wolfda/PycharmProjects/contrastive_pretrain_lightning_bolts/pl_bolts/models/self_supervised/byol/wandb/settings
2023-06-27 10:49:25,720 INFO    MainThread:2866468 [wandb_setup.py:_flush():75] Loading settings from environment variables: {'_require_service': 'True'}
2023-06-27 10:49:25,720 INFO    MainThread:2866468 [wandb_setup.py:_flush():75] Inferring run settings from compute environment: {'program_relpath': 'pl_bolts/models/self_supervised/byol/byol_module.py', 'program': '/home/wolfda/PycharmProjects/contrastive_pretrain_lightning_bolts/pl_bolts/models/self_supervised/byol/byol_module.py'}
2023-06-27 10:49:25,720 INFO    MainThread:2866468 [wandb_init.py:_log_setup():405] Logging user logs to /home/wolfda/PycharmProjects/contrastive_pretrain_lightning_bolts/pl_bolts/models/self_supervised/byol/wandb/run-20230627_104925-d522i25c/logs/debug.log
2023-06-27 10:49:25,721 INFO    MainThread:2866468 [wandb_init.py:_log_setup():406] Logging internal logs to /home/wolfda/PycharmProjects/contrastive_pretrain_lightning_bolts/pl_bolts/models/self_supervised/byol/wandb/run-20230627_104925-d522i25c/logs/debug-internal.log
2023-06-27 10:49:25,721 INFO    MainThread:2866468 [wandb_init.py:init():439] calling init triggers
2023-06-27 10:49:25,721 INFO    MainThread:2866468 [wandb_init.py:init():442] wandb.init called with sweep_config: {}
config: {}
2023-06-27 10:49:25,721 INFO    MainThread:2866468 [wandb_init.py:init():492] starting backend
2023-06-27 10:49:25,723 INFO    MainThread:2866468 [backend.py:_multiprocessing_setup():99] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-06-27 10:49:25,724 INFO    MainThread:2866468 [wandb_init.py:init():501] backend started and connected
2023-06-27 10:49:25,725 INFO    MainThread:2866468 [wandb_init.py:init():565] updated telemetry
2023-06-27 10:49:25,727 INFO    MainThread:2866468 [wandb_init.py:init():596] communicating run to backend with 30 second timeout
2023-06-27 10:49:26,132 INFO    MainThread:2866468 [wandb_run.py:_on_init():1759] communicating current version
2023-06-27 10:49:26,233 INFO    MainThread:2866468 [wandb_run.py:_on_init():1763] got version response upgrade_message: "wandb version 0.15.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-06-27 10:49:26,233 INFO    MainThread:2866468 [wandb_init.py:init():625] starting run threads in backend
2023-06-27 10:49:28,306 INFO    MainThread:2866468 [wandb_run.py:_console_start():1733] atexit reg
2023-06-27 10:49:28,307 INFO    MainThread:2866468 [wandb_run.py:_redirect():1606] redirect: SettingsConsole.WRAP
2023-06-27 10:49:28,307 INFO    MainThread:2866468 [wandb_run.py:_redirect():1643] Wrapping output streams.
2023-06-27 10:49:28,307 INFO    MainThread:2866468 [wandb_run.py:_redirect():1667] Redirects installed.
2023-06-27 10:49:28,307 INFO    MainThread:2866468 [wandb_init.py:init():664] run started, returning control to user process
2023-06-27 10:49:28,616 INFO    MainThread:2866468 [wandb_run.py:_config_callback():992] config_cb None None {'model/params/total': 70118528, 'model/params/trainable': 70118528, 'model/params/non_trainable': 0, 'tags': ['BYOL'], 'cfg/logger': True, 'cfg/checkpoint_callback': 'None', 'cfg/enable_checkpointing': True, 'cfg/default_root_dir': 'None', 'cfg/gradient_clip_val': 'None', 'cfg/gradient_clip_algorithm': 'None', 'cfg/process_position': 0, 'cfg/num_nodes': 1, 'cfg/num_processes': 'None', 'cfg/devices': 'None', 'cfg/gpus': 'None', 'cfg/auto_select_gpus': False, 'cfg/tpu_cores': 'None', 'cfg/ipus': 'None', 'cfg/log_gpu_memory': 'None', 'cfg/progress_bar_refresh_rate': 'None', 'cfg/enable_progress_bar': True, 'cfg/overfit_batches': 0.0, 'cfg/track_grad_norm': -1, 'cfg/check_val_every_n_epoch': 1, 'cfg/fast_dev_run': False, 'cfg/accumulate_grad_batches': 'None', 'cfg/max_epochs': 'None', 'cfg/min_epochs': 'None', 'cfg/max_steps': -1, 'cfg/min_steps': 'None', 'cfg/max_time': 'None', 'cfg/limit_train_batches': 'None', 'cfg/limit_val_batches': 'None', 'cfg/limit_test_batches': 'None', 'cfg/limit_predict_batches': 'None', 'cfg/val_check_interval': 'None', 'cfg/flush_logs_every_n_steps': 'None', 'cfg/log_every_n_steps': 50, 'cfg/accelerator': 'None', 'cfg/strategy': 'None', 'cfg/sync_batchnorm': False, 'cfg/precision': 32, 'cfg/enable_model_summary': True, 'cfg/weights_summary': 'top', 'cfg/weights_save_path': 'None', 'cfg/num_sanity_val_steps': 2, 'cfg/resume_from_checkpoint': 'None', 'cfg/profiler': 'None', 'cfg/benchmark': 'None', 'cfg/deterministic': False, 'cfg/reload_dataloaders_every_n_epochs': 0, 'cfg/auto_lr_find': False, 'cfg/replace_sampler_ddp': True, 'cfg/detect_anomaly': False, 'cfg/auto_scale_batch_size': False, 'cfg/prepare_data_per_node': 'None', 'cfg/plugins': 'None', 'cfg/amp_backend': 'native', 'cfg/amp_level': 'None', 'cfg/move_metrics_to_cpu': False, 'cfg/multiple_trainloader_mode': 'max_size_cycle', 'cfg/stochastic_weight_avg': False, 'cfg/terminate_on_nan': 'None', 'cfg/online_ft': False, 'cfg/dataset': 'medical', 'cfg/data_dir': '/home/wolfda/Data/PreTrain_Lung/Test_sim/Data2', 'cfg/num_workers': 8, 'cfg/batch_size': 64, 'cfg/learning_rate': 0.001, 'cfg/weight_decay': 1.5e-06, 'cfg/warmup_epochs': 1, 'cfg/meta_dir': '.', 'cfg/savepath': '/home/wolfda/Data/Spark/PreTrain/BYOL', 'cfg/offline': False, 'cfg/group': 'BYOL', 'cfg/job_type': 'Pre-training', 'cfg/tags': ['BYOL'], 'cfg/name': 'Test', 'cfg/num_classes': 1}
2023-06-27 10:49:28,634 INFO    MainThread:2866468 [wandb_run.py:_config_callback():992] config_cb None None {'num_classes': 1, 'learning_rate': 0.001, 'weight_decay': 1.5e-06, 'input_height': 32, 'batch_size': 64, 'num_workers': 8, 'warmup_epochs': 1, 'max_epochs': 'None', 'encoder_out_dim': 2048, 'projector_hidden_size': 4096, 'projector_out_dim': 256, 'logger': True, 'checkpoint_callback': 'None', 'enable_checkpointing': True, 'default_root_dir': 'None', 'gradient_clip_val': 'None', 'gradient_clip_algorithm': 'None', 'process_position': 0, 'num_nodes': 1, 'num_processes': 'None', 'devices': 'None', 'gpus': 'None', 'auto_select_gpus': False, 'tpu_cores': 'None', 'ipus': 'None', 'log_gpu_memory': 'None', 'progress_bar_refresh_rate': 'None', 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 1, 'fast_dev_run': False, 'accumulate_grad_batches': 'None', 'min_epochs': 'None', 'max_steps': -1, 'min_steps': 'None', 'max_time': 'None', 'limit_train_batches': 'None', 'limit_val_batches': 'None', 'limit_test_batches': 'None', 'limit_predict_batches': 'None', 'val_check_interval': 'None', 'flush_logs_every_n_steps': 'None', 'log_every_n_steps': 50, 'accelerator': 'None', 'strategy': 'None', 'sync_batchnorm': False, 'precision': 32, 'enable_model_summary': True, 'weights_summary': 'top', 'weights_save_path': 'None', 'num_sanity_val_steps': 2, 'resume_from_checkpoint': 'None', 'profiler': 'None', 'benchmark': 'None', 'deterministic': False, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': True, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'prepare_data_per_node': 'None', 'plugins': 'None', 'amp_backend': 'native', 'amp_level': 'None', 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'stochastic_weight_avg': False, 'terminate_on_nan': 'None', 'online_ft': False, 'dataset': 'medical', 'data_dir': '/home/wolfda/Data/PreTrain_Lung/Test_sim/Data2', 'meta_dir': '.', 'savepath': '/home/wolfda/Data/Spark/PreTrain/BYOL', 'offline': False, 'group': 'BYOL', 'job_type': 'Pre-training', 'tags': ['BYOL'], 'name': 'Test'}
